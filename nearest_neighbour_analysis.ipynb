{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c70dfc-77c5-4b43-aa9e-4e87ad7eaf5f",
   "metadata": {},
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "model.save_pretrained(\"/home/amitgajbhiye/cardiff_work/100k_data_experiments/bert_large_uncased_pretrained/model/\")\n",
    "tok = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "tok.save_pretrained(\"/home/amitgajbhiye/cardiff_work/100k_data_experiments/bert_large_uncased_pretrained/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c052c-f88c-43f4-a467-07d882f5ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import nltk\n",
    "\n",
    "from model.concept_property_model import ConceptPropertyModel\n",
    "from utils.functions import create_model\n",
    "from utils.functions import load_pretrained_model\n",
    "from utils.functions import read_config\n",
    "from utils.functions import mcrae_dataset_and_dataloader\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# assert os.environ[\"CONDA_DEFAULT_ENV\"] == \"gvenv\", \"Activate 'gvenv' conda environment\"\n",
    "\n",
    "print (f\"Device Name : {device}\")\n",
    "print (f\"Conda Environment Name : {os.environ['CONDA_DEFAULT_ENV']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b74a83-2144-40f8-9ec0-33536d84c147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pos_tagger(x):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    # print (\"tokens :\", tokens)\n",
    "    # print (\"pos tags :\", nltk.pos_tag(tokens))\n",
    "    return nltk.pos_tag(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b0e61-2bf5-49a0-9c33-fd99387ef82d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tag_adj(pos_tag_list):\n",
    "    \n",
    "    tags = [word_tag[1] for word_tag in pos_tag_list]\n",
    "    # print (\"tags :\", tags)\n",
    "    # print ([tag == \"JJ\" for tag in tags])\n",
    "    # print (all([tag == \"JJ\" for tag in tags]))\n",
    "    \n",
    "    if all ([tag == \"JJ\" for tag in tags]):\n",
    "        # print (f\"Returning True : {tags}\")\n",
    "        return True\n",
    "    else:\n",
    "        # print (f\"Returning False : {tags}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbff9b7-8be0-47ad-88f0-7671dca0115c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to count properties\n",
    "\n",
    "local_files_list = [\"data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\",\n",
    "             \"data/train_data/500k_MSCG/gkb_prop_500k_train.tsv\"]\n",
    "\n",
    "prefix_adj_local_files_list = [\"data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\"]\n",
    "\n",
    "hawk_files_list = [\"/scratch/c.scmag3/biencoder_concept_property/data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\",\n",
    "             \"/scratch/c.scmag3/biencoder_concept_property/data/train_data/500k_MSCG/gkb_prop_500k_train.tsv\"]\n",
    "\n",
    "def read_con_prop_data (files_list):\n",
    "    \n",
    "    df_list = []\n",
    "    for i, file in enumerate(files_list):\n",
    "        df_list.append(pd.read_csv(file, sep=\"\\t\", names=[\"concept\", \"property\"]))\n",
    "        \n",
    "    print (f\"Shapes of the DF read : {[df.shape for df in df_list]}\")\n",
    "    \n",
    "    df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    print (f\"Columns in concatenated DF : {df.columns}\")\n",
    "    print (f\"Concatenated DF shape : {df.shape}\")\n",
    "    \n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    df.drop_duplicates(subset=['concept', 'property'], keep=\"first\", inplace=True)\n",
    "    \n",
    "    df[\"prop_count\"] = -1\n",
    "    \n",
    "    unique_property = df[\"property\"].unique()\n",
    "    \n",
    "    print (\"num_unique_property :\", unique_property.shape, flush=True)\n",
    "    print (\"unique_property :\", unique_property, flush=True)\n",
    "    \n",
    "    df.set_index(\"property\", inplace=True)\n",
    "    \n",
    "    for i, prop in enumerate(unique_property):\n",
    "        df.loc[prop, \"prop_count\"] = df.loc[prop].shape[0]\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    df = df[[\"concept\", \"property\", \"prop_count\"]]\n",
    "    \n",
    "    df.to_csv(\"data/evaluation_data/nn_analysis/only_prefix_adj_with_prop_count.tsv\", sep='\\t', index=None, header=True)\n",
    "\n",
    "# read_con_prop_data(files_list=prefix_adj_local_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2d4d2-55fc-41b7-afc5-794073f48ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_top_k_properties(con_prop_file, pos_tag = False, cut_off = 5):\n",
    "    \n",
    "    df = pd.read_csv(con_prop_file, sep=\"\\t\", header=0)\n",
    "\n",
    "    # df.sort_values(\"prop_count\", ascending=False, inplace=True)\n",
    "\n",
    "    # print (f\"DF sorted on prop count : {df}\")\n",
    "\n",
    "    df_prop_count_cut_off = df[df[\"prop_count\"] >= cut_off]\n",
    "    \n",
    "    # df_prop_count_cut_off = df_prop_count_cut_off[0:2000]\n",
    "\n",
    "    print (f\"Dataframe with prop_count >= {cut_off} = {df_prop_count_cut_off.shape}\")\n",
    "    \n",
    "    if pos_tag:\n",
    "        df_prop_count_cut_off[\"pos_tag\"] = df_prop_count_cut_off[\"property\"].apply(pos_tagger)\n",
    "        df_prop_count_cut_off[\"is_only_adj\"] = df_prop_count_cut_off[\"pos_tag\"].apply(tag_adj)\n",
    "        df_prop_count_cut_off = df_prop_count_cut_off[df_prop_count_cut_off[\"is_only_adj\"] == True]\n",
    "        \n",
    "        adj_true_df = df_prop_count_cut_off[df_prop_count_cut_off[\"is_only_adj\"] == True]\n",
    "        \n",
    "        print (f\"adj_true_df shape {adj_true_df.shape}\")\n",
    "        print (f\"adj_true_df['property'].unique - len :\", adj_true_df['property'].unique().shape)\n",
    "        \n",
    "    \n",
    "    df_prop_count_cut_off.to_csv(\"data/evaluation_data/nn_analysis/df_with_tags.tsv\", sep=\"\\t\", index=False)\n",
    "    print (df_prop_count_cut_off)\n",
    "    \n",
    "    unique_properties = df_prop_count_cut_off[\"property\"].unique()\n",
    "    unique_properties = [x.strip().replace(\"(part)\", \"\").replace(\".\", \"\") for x in unique_properties]\n",
    "    num_unique_properties = df_prop_count_cut_off[\"property\"].unique().shape\n",
    "\n",
    "    print (f\"Number of unique properties in cut_off DF : {num_unique_properties}\")\n",
    "    # print (f\"Unique Properties are : {unique_properties}\")\n",
    "    \n",
    "    df_list = [(\"dummy\", prop, 0) for prop in unique_properties]\n",
    "\n",
    "    df_prop = pd.DataFrame.from_records(df_list)\n",
    "\n",
    "    df_prop.to_csv(\"data/evaluation_data/nn_analysis/adjs_prop_count_5_prefix_adj_plus_gkb_prop_with_prop_count.tsv\", sep=\"\\t\", index=None, header=None)\n",
    "\n",
    "# get_top_k_properties(\"data/evaluation_data/nn_analysis/hd_data/prefix_adj_plus_gkb_prop_with_prop_count.tsv\", pos_tag=True, cut_off=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb8b3d-5230-4e69-ac2a-4f5dae6963c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hd_vocab_file = \"data/evaluation_data/nn_analysis/hd_data/1A.english.vocabulary.txt\"\n",
    "test_file = \"data/evaluation_data/nn_analysis/hd_data/hd_concept_test.csv\"\n",
    "\n",
    "def preprocess_hd_data(vocab_file, test_concept_file):\n",
    "\n",
    "    with open(vocab_file,  \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [(\"con_dummy\", prop.strip(), int(0)) for prop in lines]\n",
    "        \n",
    "    con_prop_vocab_df = pd.DataFrame.from_records(lines)\n",
    "    # con_prop_vocab_df = pd.DataFrame.from_records(lines)[0:2500]\n",
    "    \n",
    "    con_prop_vocab_df.to_csv(\"data/evaluation_data/nn_analysis/hd_data/properties_hd_vocab_con_prop.tsv\", sep=\"\\t\", index=None, header=None)\n",
    "    \n",
    "    \n",
    "    test_concepts_df = pd.read_csv(test_concept_file, sep=\",\", header=0)\n",
    "    print (f\"Test Concepts DF shape : {test_concepts_df.shape}\")\n",
    "    \n",
    "    test_cons_list = test_concepts_df[\"hypo\"].unique()\n",
    "    # test_cons_list = test_concepts_df[\"hypo\"].unique()[0:10]\n",
    "    \n",
    "    \n",
    "    print (f\"Num Test Concepts : {len(test_cons_list)}\")\n",
    "    \n",
    "    test_con_prop_list = [(con.strip(), \"prop_dummy\", int(0)) for con in test_cons_list]\n",
    "    \n",
    "    test_con_prop_df  = pd.DataFrame.from_records(test_con_prop_list)\n",
    "    \n",
    "    test_con_prop_df.to_csv(\"data/evaluation_data/nn_analysis/hd_data/concepts_hd_test_con_prop.tsv\", sep=\"\\t\", index=None, header=None)\n",
    "    \n",
    "    \n",
    "# preprocess_hd_data (vocab_file = hd_vocab_file, test_concept_file= test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f9c98f-e9b2-4130-b225-68b37e16dbf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Loading the BERT Large Model for generating Property Embedding\n",
    "#### Here change the property test_file in config to the tsv file which contain the properties\n",
    "\n",
    "local_prop_config_file_path = \"configs/nn_analysis/prop_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "hawk_prop_config_file_path = \"configs/nn_analysis/hawk_prop_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "prop_config = read_config(hawk_prop_config_file_path)\n",
    "prop_model = load_pretrained_model(prop_config)\n",
    "prop_model.eval()\n",
    "prop_model.to(device)\n",
    "print(\"Property Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d02813-c5d3-4b32-b31b-9027f26f15fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the embeddings for property and concepts\n",
    "\n",
    "def get_embedding (model, config):\n",
    "    \n",
    "    print (f\"Config in get_embedding function : {config}\")\n",
    "    \n",
    "    test_dataset, test_dataloader = mcrae_dataset_and_dataloader(\n",
    "        dataset_params=config.get(\"dataset_params\"),\n",
    "        dataset_type=\"test\",\n",
    "        data_df=None,\n",
    "    )\n",
    "    \n",
    "    con_list, con_emb, prop_list, prop_emb = [], [], [], []\n",
    "\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "\n",
    "        concepts_batch, property_batch = test_dataset.add_context(batch)\n",
    "\n",
    "        ids_dict = test_dataset.tokenize(concepts_batch, property_batch)\n",
    "\n",
    "        (\n",
    "            concept_inp_id,\n",
    "            concept_attention_mask,\n",
    "            concept_token_type_id,\n",
    "            property_input_id,\n",
    "            property_attention_mask,\n",
    "            property_token_type_id,\n",
    "        ) = [val.to(device) for _, val in ids_dict.items()]\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            concept_embedding, property_embedding, logits = model(\n",
    "                concept_input_id=concept_inp_id,\n",
    "                concept_attention_mask=concept_attention_mask,\n",
    "                concept_token_type_id=concept_token_type_id,\n",
    "                property_input_id=property_input_id,\n",
    "                property_attention_mask=property_attention_mask,\n",
    "                property_token_type_id=property_token_type_id,\n",
    "            )\n",
    "            \n",
    "            print()\n",
    "            print (f\"Concepts Data :\", len(batch[0]))\n",
    "            print (f\"Concepts Data :\", batch[0])\n",
    "            print (f\"concept_embedding.shape : {concept_embedding.shape}\")\n",
    "            \n",
    "            print (f\"Property Data :\", len(batch[1]))\n",
    "            print (f\"Property Data :\", batch[1])\n",
    "            print (f\"property_embedding.shape : {property_embedding.shape}\")\n",
    "            \n",
    "            # con_vec = [(con, vec) for con, vec in zip (batch[0], concept_embedding)]    \n",
    "            # prop_vec = [(prop, vec) for prop, vec in zip(batch[1], property_embedding)]\n",
    "            \n",
    "            con_list.extend(batch[0])\n",
    "            con_emb.extend(concept_embedding)\n",
    "            \n",
    "            prop_list.extend(batch[1])\n",
    "            prop_emb.extend(property_embedding)\n",
    "            \n",
    "    con_emb = [x.cpu().numpy() for x in con_emb]\n",
    "    prop_emb = [x.cpu().numpy() for x in prop_emb]\n",
    "    \n",
    "    return con_list, con_emb, prop_list, prop_emb\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81061a-83a9-4263-8bb6-7d88653e120f",
   "metadata": {
    "tags": []
   },
   "source": [
    "_, _, prop_list, prop_emb = get_embedding(prop_model, prop_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d8bf6-ba1c-480b-82a9-4f03eb9f2aca",
   "metadata": {},
   "source": [
    "print (f\"prop_list len - {len(prop_list)}, Property Emb Len - {len(prop_emb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b67cb8-4477-4f5a-94cd-d3d003ac2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(vecs):\n",
    "    \n",
    "    maxnorm = max([np.linalg.norm(v) for v in vecs])\n",
    "    new_vecs = []\n",
    "    \n",
    "    for v in vecs:\n",
    "        new_vecs.append(np.insert(v, 0, np.sqrt(maxnorm**2-np.linalg.norm(v)**2)))\n",
    "    \n",
    "    return new_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448f26f-598e-4c6e-89d8-a57ad165317c",
   "metadata": {
    "tags": []
   },
   "source": [
    "prop_trans = transform(prop_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6e0d2c-3994-4488-8019-5caff1a5d094",
   "metadata": {},
   "source": [
    "prop_name_emb_dict = {\"name_list_prop\" : prop_list,\n",
    "                      \"untransformed_prop_emb\":prop_emb,\n",
    "                     \"transformed_prop_emb\" : prop_trans}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f6b150-9741-4c12-bd4e-a6a6ddd1bdd7",
   "metadata": {},
   "source": [
    "print (f\"Pickling the transformed property name list and their embeddings.\")\n",
    "\n",
    "with open (\"data/evaluation_data/nn_analysis/hd_data/hd_prop_name_emb.pickle\", \"wb\") as f:\n",
    "    pickle.dump(prop_name_emb_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d45c8-3796-46ce-8d35-28ae8c009f46",
   "metadata": {},
   "source": [
    "for key, value in prop_name_emb_dict.items():\n",
    "    print (f\"{key} : {len(value)}\")\n",
    "\n",
    "print ()\n",
    "print (\"*\" * 50)\n",
    "print (*prop_list, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2b3ca-f28b-4cc9-a17a-ca3c96802f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b1b46-d79a-4fbf-b1ce-32056bc61804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8e5369-797b-4d14-aa6c-52a5efa6e189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the model model to generate concept embeddings\n",
    "# Here change the concept test file the file where the test (query) concepts are loaded\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "local_con_conf_file_path = \"configs/nn_analysis/con_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "hawk_con_conf_file_path = \"configs/nn_analysis/hawk_con_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "\n",
    "con_config = read_config(hawk_con_conf_file_path)\n",
    "con_model = load_pretrained_model(con_config)\n",
    "con_model.eval()\n",
    "con_model.to(device)\n",
    "print (\"Concept Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327b3b4-493c-4434-9549-07cadeee0d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "con_list, con_emb, _, _ = get_embedding(con_model, con_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12be26-f441-42c0-aabf-ff87912eb0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"con_list len - {len(con_list)}, con_emb Len - {len(con_emb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ddf80-562d-45b0-aaaf-e4ac199710d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trans = transform(con_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9bf4ee-3730-41ab-a97e-f64b4924e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_name_emb_dict = {\"name_list_con\" : con_list,\n",
    "                     \"untransformed_con_emb\": con_emb,\n",
    "                    \"transformed_con_emb\" : con_trans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2efd0-795c-4e5f-b710-5a20ed6bdb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data/evaluation_data/nn_analysis/hd_data/hd_con_name_emb.pickle\", \"wb\") as f:\n",
    "    pickle.dump(con_name_emb_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9735418e-ced0-4461-8e50-78182aed9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in con_name_emb_dict.items():\n",
    "    print (f\"{key} : {len(value)}\")\n",
    "\n",
    "print ()\n",
    "print (\"*\" * 50)\n",
    "print (*con_list, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ded99-c28f-4945-838b-19e1d08cc779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1335eb-4fcb-44fb-9eaf-080952fad7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bf51d-6799-44c0-bfc7-73ace6788cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1ea95-1817-454c-b86c-63077a4b6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hd_con_emb_file = \"/home/amitgajbhiye/cardiff_work/dot_product_model_nn_analysis/hd_con_name_emb.pickle\"\n",
    "hd_prop_emb_file = \"/home/amitgajbhiye/cardiff_work/dot_product_model_nn_analysis/hd_prop_name_emb.pickle\"\n",
    "\n",
    "with open(hd_con_emb_file, \"rb\") as con_emb, open(hd_prop_emb_file, \"rb\") as prop_emb:\n",
    "    \n",
    "    con_name_emb = pickle.load(con_emb)\n",
    "    prop_name_emb = pickle.load(prop_emb)\n",
    "\n",
    "print (con_name_emb.keys())\n",
    "print (prop_name_emb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a426bf-7ef8-43d5-b9fa-9f4e57d3fcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'Number of Properties in the loaded prop pickel : {len(prop_name_emb.get(\"name_list_prop\"))}', flush=True)\n",
    "print (f'Number of Untransformed Properties Embedding in the loaded prop pickel : {len(prop_name_emb.get(\"untransformed_prop_emb\"))}', flush=True)\n",
    "print (f'Number of TRansformed Properties Embedding in the loaded prop pickel : {len(prop_name_emb.get(\"transformed_prop_emb\"))}', flush=True)\n",
    "\n",
    "print ()\n",
    "print (f'Number of Concepts in the loaded con pickel : {len(con_name_emb.get(\"name_list_con\"))}', flush=True)\n",
    "print (f'Number of Untransformed Concepts Embedding in the loaded prop pickel : {len(con_name_emb.get(\"untransformed_con_emb\"))}', flush=True)\n",
    "print (f'Number of Transformed Concepts Embedding in the loaded prop pickel : {len(con_name_emb.get(\"transformed_con_emb\"))}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ad1f4-2e9b-4263-a3d4-d2d9786a607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name_emb.get(\"transformed_prop_emb\")[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7712c887-8dd4-4fa7-a7e8-7881adb1ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nearest_neighbours = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99a0b8-fce8-497b-b522-ac66ee79b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Nearest Neighbours\n",
    "nbrs = NearestNeighbors(n_neighbors=num_nearest_neighbours, algorithm='brute').fit(np.array(prop_name_emb.get(\"transformed_prop_emb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c7389-80db-43b5-857d-e5ed7901aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = nbrs.kneighbors(np.array(con_name_emb.get(\"transformed_con_emb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075bc87-efc0-43ea-ad66-f10c398735a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (indices)\n",
    "print (indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde48f25-6b74-46f9-955e-2e70a8105659",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (con_name_emb.keys())\n",
    "print (prop_name_emb.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc767e5-073a-494a-87b1-6f2bdb7774ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prop_name_emb.get(\"untransformed_prop_emb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693b987-ff50-46d2-88b0-1fa7ff49a578",
   "metadata": {},
   "source": [
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):    \n",
    "    print (f\"{con} : {[prop_name_emb.get('name_list_prop') [prop_id] for prop_id in idx]}\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdf071-05c1-401f-b627-7c134d612c3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, con in zip(indices[0:5], con_name_emb.get(\"name_list_con\")[0:5]):    \n",
    "    print (f\"{con} : {[prop_name_emb.get('name_list_prop') [prop_id] for prop_id in idx]}\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b2407-2d47-409f-887d-93d4faa5e96e",
   "metadata": {
    "tags": []
   },
   "source": [
    "d = {}\n",
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):\n",
    "    d[con] = [prop_name_emb.get('name_list_prop') [prop_id].strip() for prop_id in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6ad07-7456-4f1f-bfbb-eec2c8b853b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pos_tagger(x):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    # print (\"tokens :\", tokens)\n",
    "    # print (\"pos tags :\", nltk.pos_tag(tokens))\n",
    "    return nltk.pos_tag(tokens)\n",
    "    \n",
    "\n",
    "def filter_prop (con, prop_list):\n",
    "    \n",
    "    filtered_prop_list = []\n",
    "    \n",
    "    con = con.lower().strip()\n",
    "    prop_list = [prop.lower().strip() for prop in prop_list]\n",
    "    \n",
    "    for prop in prop_list:\n",
    "        if (con not in prop) and (prop not in con) :\n",
    "            # print (f\"{con} : {prop}, {pos_tagger(prop)}, {pos_tagger(prop)[-1]}\")\n",
    "            \n",
    "            if pos_tagger(prop)[-1][1] in (\"NN\",\"NNS\",\"NNPS\"):\n",
    "                filtered_prop_list.append(prop)\n",
    "        \n",
    "            # print (f\"filtered_prop_list : {filtered_prop_list}\")\n",
    "    \n",
    "    print (len(filtered_prop_list))\n",
    "    print (filtered_prop_list)\n",
    "    print ()\n",
    "    \n",
    "    filtered_prop_list = [prop.strip() for prop in filtered_prop_list]\n",
    "\n",
    "    if len(filtered_prop_list) >= 15:\n",
    "        return filtered_prop_list[0:15]\n",
    "    else:\n",
    "        return filtered_prop_list\n",
    "\n",
    "    \n",
    "\n",
    "d = {}\n",
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):\n",
    "    \n",
    "    filtered_prop_list = []\n",
    "    \n",
    "    prop_for_con = [prop_name_emb.get('name_list_prop') [prop_id].strip() for prop_id in idx]\n",
    "    \n",
    "    print (f\"concept : {con}\")\n",
    "    print (f\"All properties : {prop_for_con}\")\n",
    "    print ([pos_tagger(prop) for prop in prop_for_con] )\n",
    "    filtered_prop_list = filter_prop(con, prop_for_con)\n",
    "    \n",
    "    d[con] = filtered_prop_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f310aafb-3d26-4d1f-93d3-c6b4d1b01da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for key, value in d.items():\n",
    "    print (f\"{key} : {len(value)}\")\n",
    "    \n",
    "    l.append(len(value))\n",
    "\n",
    "counts = Counter(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66985cf5-a4e2-47b4-b8c8-ed80492a4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7790ee-7f4c-4576-ab4d-47e0f73c6c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(d.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00345659-bae1-43de-812d-4ab46d6615d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(d, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903a221-84c6-4591-8fff-678e65729a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef5b9d-4907-475f-a2af-35fdd2a9e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0d640-0222-4645-a3ff-7effe5e7e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25fcd1-ca1e-4592-93aa-2b11c9a04148",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_hyper_file_name = \"/home/amitgajbhiye/cardiff_work/dot_product_model_nn_analysis/filtered_hd_test_results.csv\"\n",
    "columns =[\"hypo\",\"hyp=1\",\"hyp=2\",\"hyp=3\",\"hyp=4\",\"hyp=5\",\"hyp=6\",\"hyp=7\",\"hyp=8\",\"hyp=9\",\"hyp=10\",\"hyp=11\",\"hyp=12\",\"hyp=13\",\"hyp=14\",\"hyp=15\"]\n",
    "\n",
    "df.columns = columns\n",
    "\n",
    "df[\"hypo\"] = df[\"hypo\"].str.strip()\n",
    "\n",
    "df.to_csv(hypo_hyper_file_name, sep = \",\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0b0e94-788e-4adf-8af0-40c249016a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd507a-5e50-498c-927e-d6e1f9e471b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3854e7e-d45e-4b83-b598-16990acd6623",
   "metadata": {},
   "source": [
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):\n",
    "    print (f\"{con} : {[prop_name_emb.get('name_list_prop') [prop_id] for prop_id in idx]}\\n\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5087f8c-4b8c-45c2-9a19-7c5f9910de66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5ced1-b1a6-4b71-a37c-e76787d199c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
