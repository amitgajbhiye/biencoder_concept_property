{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c70dfc-77c5-4b43-aa9e-4e87ad7eaf5f",
   "metadata": {},
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "model.save_pretrained(\"/home/amitgajbhiye/cardiff_work/100k_data_experiments/bert_large_uncased_pretrained/model/\")\n",
    "tok = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "tok.save_pretrained(\"/home/amitgajbhiye/cardiff_work/100k_data_experiments/bert_large_uncased_pretrained/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889c052c-f88c-43f4-a467-07d882f5ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device Name : cuda\n",
      "Conda Environment Name : gvenv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from model.concept_property_model import ConceptPropertyModel\n",
    "from utils.functions import create_model\n",
    "from utils.functions import load_pretrained_model\n",
    "from utils.functions import read_config\n",
    "from utils.functions import mcrae_dataset_and_dataloader\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# assert os.environ[\"CONDA_DEFAULT_ENV\"] == \"gvenv\", \"Activate 'gvenv' conda environment\"\n",
    "\n",
    "print (f\"Device Name : {device}\")\n",
    "print (f\"Conda Environment Name : {os.environ['CONDA_DEFAULT_ENV']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b74a83-2144-40f8-9ec0-33536d84c147",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pos_tagger(x):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    # print (\"tokens :\", tokens)\n",
    "    # print (\"pos tags :\", nltk.pos_tag(tokens))\n",
    "    return nltk.pos_tag(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6b0e61-2bf5-49a0-9c33-fd99387ef82d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tag_adj(pos_tag_list):\n",
    "    \n",
    "    tags = [word_tag[1] for word_tag in pos_tag_list]\n",
    "    # print (\"tags :\", tags)\n",
    "    # print ([tag == \"JJ\" for tag in tags])\n",
    "    # print (all([tag == \"JJ\" for tag in tags]))\n",
    "    \n",
    "    if all ([tag == \"JJ\" for tag in tags]):\n",
    "        # print (f\"Returning True : {tags}\")\n",
    "        return True\n",
    "    else:\n",
    "        # print (f\"Returning False : {tags}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b32e87be-f9d6-4c5f-84e4-8a2ec804894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_noun(pos_tag_list):\n",
    "    \n",
    "    tags = [word_tag[1] for word_tag in pos_tag_list]\n",
    "    \n",
    "    if  tags[-1] in (\"NN\",\"NNS\",\"NNPS\"):\n",
    "        # print (f\"Returning True : {tags}\")\n",
    "        return True\n",
    "    else:\n",
    "        # print (f\"Returning False : {tags}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbff9b7-8be0-47ad-88f0-7671dca0115c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to count properties\n",
    "\n",
    "local_files_list = [\"data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\",\n",
    "             \"data/train_data/500k_MSCG/gkb_prop_500k_train.tsv\"]\n",
    "\n",
    "prefix_adj_local_files_list = [\"data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\"]\n",
    "\n",
    "hawk_files_list = [\"/scratch/c.scmag3/biencoder_concept_property/data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\",\n",
    "             \"/scratch/c.scmag3/biencoder_concept_property/data/train_data/500k_MSCG/gkb_prop_500k_train.tsv\"]\n",
    "\n",
    "def read_con_prop_data (files_list):\n",
    "    \n",
    "    df_list = []\n",
    "    for i, file in enumerate(files_list):\n",
    "        df_list.append(pd.read_csv(file, sep=\"\\t\", names=[\"concept\", \"property\"]))\n",
    "        \n",
    "    print (f\"Shapes of the DF read : {[df.shape for df in df_list]}\")\n",
    "    \n",
    "    df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    print (f\"Columns in concatenated DF : {df.columns}\")\n",
    "    print (f\"Concatenated DF shape : {df.shape}\")\n",
    "    \n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    df.drop_duplicates(subset=['concept', 'property'], keep=\"first\", inplace=True)\n",
    "    \n",
    "    df[\"prop_count\"] = -1\n",
    "    \n",
    "    unique_property = df[\"property\"].unique()\n",
    "    \n",
    "    print (\"num_unique_property :\", unique_property.shape, flush=True)\n",
    "    print (\"unique_property :\", unique_property, flush=True)\n",
    "    \n",
    "    df.set_index(\"property\", inplace=True)\n",
    "    \n",
    "    for i, prop in enumerate(unique_property):\n",
    "        df.loc[prop, \"prop_count\"] = df.loc[prop].shape[0]\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    df = df[[\"concept\", \"property\", \"prop_count\"]]\n",
    "    \n",
    "    df.to_csv(\"data/evaluation_data/nn_analysis/only_prefix_adj_with_prop_count.tsv\", sep='\\t', index=None, header=True)\n",
    "\n",
    "# read_con_prop_data(files_list=prefix_adj_local_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2d4d2-55fc-41b7-afc5-794073f48ae3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_top_k_properties(con_prop_file, pos_tag = False, cut_off = 5):\n",
    "    \n",
    "    df = pd.read_csv(con_prop_file, sep=\"\\t\", header=0)\n",
    "\n",
    "    # df.sort_values(\"prop_count\", ascending=False, inplace=True)\n",
    "\n",
    "    # print (f\"DF sorted on prop count : {df}\")\n",
    "\n",
    "    df_prop_count_cut_off = df[df[\"prop_count\"] >= cut_off]\n",
    "    \n",
    "    # df_prop_count_cut_off = df_prop_count_cut_off[0:2000]\n",
    "\n",
    "    print (f\"Dataframe with prop_count >= {cut_off} = {df_prop_count_cut_off.shape}\")\n",
    "    \n",
    "    if pos_tag:\n",
    "        df_prop_count_cut_off[\"pos_tag\"] = df_prop_count_cut_off[\"property\"].apply(pos_tagger)\n",
    "        \n",
    "        df_prop_count_cut_off[\"is_only_adj\"] = df_prop_count_cut_off[\"pos_tag\"].apply(tag_adj)\n",
    "        \n",
    "        df_prop_count_cut_off[\"is_last_word_noun\"] = df_prop_count_cut_off[\"pos_tag\"].apply(tag_noun)\n",
    "        \n",
    "        \n",
    "    df_prop_count_cut_off.to_csv(\"data/evaluation_data/nn_analysis/df_with_adj_and_noun_tags.tsv\", sep=\"\\t\", index=False)\n",
    "    print (df_prop_count_cut_off)\n",
    "    \n",
    "    \n",
    "    df_is_only_adj = df_prop_count_cut_off[df_prop_count_cut_off[\"is_only_adj\"] == True]\n",
    "    \n",
    "    adj_file_name = \"data/evaluation_data/nn_analysis/prefix_plus_gkb_df_with_only_adj_properties.tsv\"\n",
    "    df_is_only_adj.to_csv(adj_file_name, sep=\"\\t\", index=None, header=None)\n",
    "    \n",
    "    unique_adj_prop = df_is_only_adj[\"property\"].unique()\n",
    "    unique_adj_prop = [x.strip().replace(\"(part)\", \"\").replace(\".\", \"\") for x in unique_adj_prop]\n",
    "    unique_adj_prop = [(\"dummy_con\", prop, 0) for prop in unique_adj_prop]\n",
    "    df_unique_adj_prop = pd.DataFrame.from_records(unique_adj_prop)\n",
    "    \n",
    "    df_adj_prop_file_name = \"data/evaluation_data/nn_analysis/adj_properties.tsv\"\n",
    "    df_unique_adj_prop.to_csv(df_adj_prop_file_name, sep=\"\\t\", header=None, index=None)\n",
    "    \n",
    "    print (f\"df_is_only_adj.shape : {df_is_only_adj.shape}\")\n",
    "    print (\"Adjective Unique Property\", len(unique_adj_prop))\n",
    "    \n",
    "    \n",
    "    print ()\n",
    "    df_last_word_noun = df_prop_count_cut_off[df_prop_count_cut_off[\"is_last_word_noun\"] == True]\n",
    "    print (f\"df_last_word_noun.shape : {df_last_word_noun.shape}\")\n",
    "    \n",
    "    noun_file_name = \"data/evaluation_data/nn_analysis/prefix_plus_gkb_df_with_last_word_noun_properties.tsv\"\n",
    "    df_last_word_noun.to_csv(noun_file_name, sep=\"\\t\", index=None, header=None)\n",
    "    \n",
    "    unique_last_word_noun = df_last_word_noun[\"property\"].unique()\n",
    "    \n",
    "    print (\"unique_last_word_noun : \", len(unique_last_word_noun))\n",
    "    \n",
    "    unique_last_word_noun = [x.strip().replace(\"(part)\", \"\").replace(\".\", \"\") for x in unique_last_word_noun]\n",
    "    unique_last_word_noun = [(\"dummy_con\", prop, 0) for prop in unique_last_word_noun]\n",
    "    \n",
    "    df_unique_last_word_noun = pd.DataFrame.from_records(unique_last_word_noun)\n",
    "    df_unique_last_word_noun_file_name = \"data/evaluation_data/nn_analysis/noun_properties.tsv\"\n",
    "    \n",
    "    df_unique_last_word_noun.to_csv(df_unique_last_word_noun_file_name, sep=\"\\t\", header=None, index=None)\n",
    "\n",
    "    print (f\"df_unique_last_word_noun.shape : {df_unique_last_word_noun.shape}\")\n",
    "    print (\"Noun Unique Property\", len(unique_last_word_noun))\n",
    "    \n",
    "    \n",
    "con_prop_file_with_counts = \"data/evaluation_data/nn_analysis/prefix_adj_plus_gkb_prop_with_prop_count.tsv\"\n",
    "    \n",
    "# get_top_k_properties(con_prop_file_with_counts, pos_tag=True, cut_off=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446b487-ba40-469c-9f01-b9234467eac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0adb8b3d-5230-4e69-ac2a-4f5dae6963c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Concepts DF shape : (358, 16)\n",
      "test_concepts_df\n",
      "                 hypo                  hyp=1                          hyp=2  \\\n",
      "0                 air           musical work                  hip hop music   \n",
      "1             musical            music genre                  musical style   \n",
      "2            theremin  electronic instrument  electronic musical instrument   \n",
      "3                glam           classic rock                           rock   \n",
      "4               shred                   rock                    music genre   \n",
      "..                ...                    ...                            ...   \n",
      "353  british invasion           classic rock                           rock   \n",
      "354   hillbilly music                country                  country music   \n",
      "355           tom-tom                   drum                  membranophone   \n",
      "356          clarinet                   wood            woodwind instrument   \n",
      "357         cool jazz                   jazz                  popular music   \n",
      "\n",
      "                     hyp=3                  hyp=4                  hyp=5  \\\n",
      "0                  hip hop                    rap              rap music   \n",
      "1                      NaN                    NaN                    NaN   \n",
      "2               instrument     musical instrument                    NaN   \n",
      "3              music genre          musical style                    NaN   \n",
      "4            musical style                    NaN                    NaN   \n",
      "..                     ...                    ...                    ...   \n",
      "353            music genre          musical style                    NaN   \n",
      "354  country-western music    country and western          musical style   \n",
      "355             percussion  percussive instrument  percussion instrument   \n",
      "356               woodwind             instrument     musical instrument   \n",
      "357    popular music genre          musical style            music genre   \n",
      "\n",
      "           hyp=6               hyp=7          hyp=8                 hyp=9  \\\n",
      "0        hip-hop                band  musical group  musical organization   \n",
      "1            NaN                 NaN            NaN                   NaN   \n",
      "2            NaN                 NaN            NaN                   NaN   \n",
      "3            NaN                 NaN            NaN                   NaN   \n",
      "4            NaN                 NaN            NaN                   NaN   \n",
      "..           ...                 ...            ...                   ...   \n",
      "353          NaN                 NaN            NaN                   NaN   \n",
      "354  music genre   traditional music           folk                folkie   \n",
      "355   instrument  musical instrument            NaN                   NaN   \n",
      "356         reed     reed instrument           wind       wind instrument   \n",
      "357          NaN                 NaN            NaN                   NaN   \n",
      "\n",
      "          hyp=10        hyp=11     hyp=12        hyp=13               hyp=14  \\\n",
      "0    music group    rock group  rock band          team  musical composition   \n",
      "1            NaN           NaN        NaN           NaN                  NaN   \n",
      "2            NaN           NaN        NaN           NaN                  NaN   \n",
      "3            NaN           NaN        NaN           NaN                  NaN   \n",
      "4            NaN           NaN        NaN           NaN                  NaN   \n",
      "..           ...           ...        ...           ...                  ...   \n",
      "353          NaN           NaN        NaN           NaN                  NaN   \n",
      "354   folk music  ethnic music       tune  pop musician            pop music   \n",
      "355          NaN           NaN        NaN           NaN                  NaN   \n",
      "356    aerophone           NaN        NaN           NaN                  NaN   \n",
      "357          NaN           NaN        NaN           NaN                  NaN   \n",
      "\n",
      "             hyp=15  \n",
      "0    piece of music  \n",
      "1               NaN  \n",
      "2               NaN  \n",
      "3               NaN  \n",
      "4               NaN  \n",
      "..              ...  \n",
      "353             NaN  \n",
      "354             pop  \n",
      "355             NaN  \n",
      "356             NaN  \n",
      "357             NaN  \n",
      "\n",
      "[358 rows x 16 columns]\n",
      "Num Test Concepts : 358\n"
     ]
    }
   ],
   "source": [
    "# hd_vocab_file = \"data/evaluation_data/nn_analysis/hd_data/1A.english.vocabulary.txt\"\n",
    "# test_file = \"data/evaluation_data/nn_analysis/hd_data/hd_concept_test.csv\"\n",
    "\n",
    "\n",
    "music_hd_vocab = \"data/evaluation_data/nn_analysis/music_hd/2B.music.vocabulary.txt\"\n",
    "music_hd_test = \"data/evaluation_data/nn_analysis/music_hd/music__hd_concept_test.csv\"\n",
    "\n",
    "def preprocess_hd_data(vocab_file, test_concept_file):\n",
    "\n",
    "    with open(vocab_file,  \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [(\"con_dummy\", prop.strip(), int(0)) for prop in lines]\n",
    "        \n",
    "    con_prop_vocab_df = pd.DataFrame.from_records(lines)\n",
    "    con_prop_vocab_df = pd.DataFrame.from_records(lines)[0:2500]\n",
    "    \n",
    "    con_prop_vocab_df.to_csv(\"data/evaluation_data/nn_analysis/music_hd/properties_music_hd_vocab_con_prop.tsv\", sep=\"\\t\", index=None, header=None)\n",
    "    \n",
    "    \n",
    "    test_concepts_df = pd.read_csv(test_concept_file, sep=\",\", header=0)\n",
    "    print (f\"Test Concepts DF shape : {test_concepts_df.shape}\")\n",
    "    print (\"test_concepts_df\")\n",
    "    print (test_concepts_df)\n",
    "    \n",
    "    \n",
    "    test_cons_list = test_concepts_df[\"hypo\"].unique()\n",
    "    # test_cons_list = test_concepts_df[\"hypo\"].unique()[0:10]\n",
    "    \n",
    "    print (f\"Num Test Concepts : {len(test_cons_list)}\")\n",
    "    \n",
    "    test_con_prop_list = [(con.strip(), \"prop_dummy\", int(0)) for con in test_cons_list]\n",
    "    \n",
    "    test_con_prop_df  = pd.DataFrame.from_records(test_con_prop_list)\n",
    "    \n",
    "    test_con_prop_df.to_csv(\"data/evaluation_data/nn_analysis/music_hd/concepts_music_hd_test_con_prop.tsv\", sep=\"\\t\", index=None, header=None)\n",
    "    \n",
    "    \n",
    "preprocess_hd_data (vocab_file = music_hd_vocab, test_concept_file = music_hd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443734d0-6ea0-4d16-bc82-a02434022ee1",
   "metadata": {},
   "source": [
    "con_prop_file = \"data/evaluation_data/nn_analysis/prefix_adj_plus_gkb_prop_with_prop_count.tsv\"\n",
    "\n",
    "con_prop_df = pd.read_csv(con_prop_file, sep=\"\\t\", header=0)\n",
    "\n",
    "print (con_prop_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51743d2b-5239-4be5-888d-9ec9d0eab94a",
   "metadata": {},
   "source": [
    "\n",
    "file_cut_off_prop_count_10_unique = \"data/evaluation_data/nn_analysis/cut_off_prop_count_10_unique.tsv\"\n",
    "\n",
    "cut_off_prop_count_10 = con_prop_df[con_prop_df[\"prop_count\"] >= 10]\n",
    "\n",
    "cut_off_prop_count_10.drop(\"prop_count\", axis=1, inplace=True)\n",
    "\n",
    "unique_prop_list = cut_off_prop_count_10[\"property\"].unique()\n",
    "\n",
    "print (\"Unique Prop Count :\", len(unique_prop_list))\n",
    "\n",
    "unique_prop_list = [(\"dummy_con\", prop.strip(), int(0)) for prop in unique_prop_list]\n",
    "\n",
    "unique_prop_df = pd.DataFrame(unique_prop_list)\n",
    "\n",
    "unique_prop_df.to_csv(file_cut_off_prop_count_10_unique, sep=\"\\t\", header=None, index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967ee14-f9fb-41c9-bc04-7faa1f6a4332",
   "metadata": {},
   "source": [
    "mc_train_file = \"data/evaluation_data/extended_mcrae/train_mcrae.tsv\"\n",
    "\n",
    "train_df = pd.read_csv(mc_train_file, sep=\"\\t\", names=[\"concept\", \"property\", \"label\"])\n",
    "\n",
    "unique_train_con = train_df[\"concept\"].unique()\n",
    "unique_train_con = [(con.strip(), \"dummy_prop\", int(0)) for con in unique_train_con]\n",
    "\n",
    "unique_train_df = pd.DataFrame.from_records(unique_train_con)\n",
    "unique_train_df.to_csv(\"data/evaluation_data/nn_analysis/mcrae_unique_train_concepts.tsv\", sep=\"\\t\", header=None, index=None)\n",
    "\n",
    "\n",
    "unique_train_prop = train_df[\"property\"].unique()\n",
    "unique_train_prop = [(\"dummy_con\", prop.strip(), int(0)) for prop in unique_train_prop]\n",
    "\n",
    "unique_train_prop_df = pd.DataFrame.from_records(unique_train_prop)\n",
    "\n",
    "unique_train_prop_df.to_csv(\"data/evaluation_data/nn_analysis/mcrae_unique_train_properties.tsv\", sep=\"\\t\", header=None, index=None)\n",
    "\n",
    "\n",
    "print (len(unique_train_con))\n",
    "print (len(unique_train_prop))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c2d7a9-9bd9-4da7-a98c-c1f110615f5e",
   "metadata": {},
   "source": [
    "mc_test_file = \"data/evaluation_data/extended_mcrae/test_mcrae.tsv\"\n",
    "\n",
    "test_df = pd.read_csv(mc_test_file, sep=\"\\t\", names=[\"concept\", \"property\", \"label\"])\n",
    "\n",
    "unique_test_con = test_df[\"concept\"].unique()\n",
    "unique_test_con = [(con.strip(), \"dummy_prop\", int(0)) for con in unique_test_con]\n",
    "\n",
    "unique_test_df = pd.DataFrame.from_records(unique_test_con)\n",
    "unique_test_df.to_csv(\"data/evaluation_data/nn_analysis/mcrae_unique_test_concepts.tsv\", sep=\"\\t\", header=None, index=None)\n",
    "\n",
    "\n",
    "unique_test_prop = test_df[\"property\"].unique()\n",
    "unique_test_prop = [(\"dummy_con\", prop.strip(), int(0)) for prop in unique_test_prop]\n",
    "\n",
    "unique_test_prop_df = pd.DataFrame.from_records(unique_test_prop)\n",
    "\n",
    "unique_test_prop_df.to_csv(\"data/evaluation_data/nn_analysis/mcrae_unique_test_properties.tsv\", sep=\"\\t\", header=None, index=None)\n",
    "\n",
    "\n",
    "print (len(unique_test_con))\n",
    "print (len(unique_test_prop))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfecb963-f36c-4627-b14b-501ae374e8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ae26b-73c8-422d-bfb5-438377fecbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8056a8-3ab1-459c-8146-bb8ae1d6a9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(vecs):\n",
    "    \n",
    "    maxnorm = max([np.linalg.norm(v) for v in vecs])\n",
    "    new_vecs = []\n",
    "    \n",
    "    for v in vecs:\n",
    "        new_vecs.append(np.insert(v, 0, np.sqrt(maxnorm**2-np.linalg.norm(v)**2)))\n",
    "    \n",
    "    return new_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd013dfc-3a84-40f5-956c-2d9c5c6adec9",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d02813-c5d3-4b32-b31b-9027f26f15fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the embeddings for property and concepts\n",
    "\n",
    "def get_embedding (model, config):\n",
    "    \n",
    "    print (f\"Config in get_embedding function : {config}\")\n",
    "    \n",
    "    test_dataset, test_dataloader = mcrae_dataset_and_dataloader(\n",
    "        dataset_params=config.get(\"dataset_params\"),\n",
    "        dataset_type=\"test\",\n",
    "        data_df=None,\n",
    "    )\n",
    "    \n",
    "    con_list, con_emb, prop_list, prop_emb = [], [], [], []\n",
    "\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "\n",
    "        concepts_batch, property_batch = test_dataset.add_context(batch)\n",
    "\n",
    "        ids_dict = test_dataset.tokenize(concepts_batch, property_batch)\n",
    "\n",
    "        (\n",
    "            concept_inp_id,\n",
    "            concept_attention_mask,\n",
    "            concept_token_type_id,\n",
    "            property_input_id,\n",
    "            property_attention_mask,\n",
    "            property_token_type_id,\n",
    "        ) = [val.to(device) for _, val in ids_dict.items()]\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            concept_embedding, property_embedding, logits = model(\n",
    "                concept_input_id=concept_inp_id,\n",
    "                concept_attention_mask=concept_attention_mask,\n",
    "                concept_token_type_id=concept_token_type_id,\n",
    "                property_input_id=property_input_id,\n",
    "                property_attention_mask=property_attention_mask,\n",
    "                property_token_type_id=property_token_type_id,\n",
    "            )\n",
    "            \n",
    "            print()\n",
    "            print (f\"Concepts Data :\", len(batch[0]))\n",
    "            print (f\"Concepts Data :\", batch[0])\n",
    "            print (f\"concept_embedding.shape : {concept_embedding.shape}\")\n",
    "            \n",
    "            print (f\"Property Data :\", len(batch[1]))\n",
    "            print (f\"Property Data :\", batch[1])\n",
    "            print (f\"property_embedding.shape : {property_embedding.shape}\")\n",
    "            \n",
    "            # con_vec = [(con, vec) for con, vec in zip (batch[0], concept_embedding)]    \n",
    "            # prop_vec = [(prop, vec) for prop, vec in zip(batch[1], property_embedding)]\n",
    "            \n",
    "            con_list.extend(batch[0])\n",
    "            con_emb.extend(concept_embedding)\n",
    "            \n",
    "            prop_list.extend(batch[1])\n",
    "            prop_emb.extend(property_embedding)\n",
    "            \n",
    "    con_emb = [x.cpu().numpy() for x in con_emb]\n",
    "    prop_emb = [x.cpu().numpy() for x in prop_emb]\n",
    "    \n",
    "    return con_list, con_emb, prop_list, prop_emb\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53bb9f-c964-4333-867d-182b77da26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loading the BERT Large Model for generating Property Embedding\n",
    "#### Here change the property test_file in config to the tsv file which contain the properties\n",
    "\n",
    "local_prop_config_file_path = \"configs/nn_analysis/prop_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "hawk_bert_large_prop_config_file_path = \"configs/nn_analysis/hawk_prop_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "\n",
    "hawk_bert_base_prop_config_file_path = \"configs/nn_analysis/hawk_prop_nn_analysis_bert_base_fine_tune_mscg_adj_gkb_config.json\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "prop_config = read_config(hawk_bert_base_prop_config_file_path)\n",
    "prop_model = load_pretrained_model(prop_config)\n",
    "prop_model.eval()\n",
    "prop_model.to(device)\n",
    "print(\"Property Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c5569-5bff-44c1-ae3e-739a7b92b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, prop_list, prop_emb = get_embedding(prop_model, prop_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a49525-7a47-4f01-94ba-f1666b9cb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"prop_list len - {len(prop_list)}, Property Emb Len - {len(prop_emb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d948c27-396e-4deb-b675-63bfd7f7c36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_trans = transform(prop_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b5dea-379c-407d-a822-4182e2947894",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name_emb_dict = {\"name_list_prop\" : prop_list,\n",
    "                      \"untransformed_prop_emb\":prop_emb,\n",
    "                     \"transformed_prop_emb\" : prop_trans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd81a9-b792-4070-8d0a-226319057cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Pickling the transformed property name list and their embeddings.\")\n",
    "\n",
    "pickle_file_name = \"/scratch/c.scmag3/biencoder_concept_property/data/evaluation_data/nn_analysis/mcrae_bert_base_test_prop_embeds.pkl\"\n",
    "\n",
    "with open (pickle_file_name, \"wb\") as f:\n",
    "    pickle.dump(prop_name_emb_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a956f-2a2c-4709-aa5d-732dcf5dfef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in prop_name_emb_dict.items():\n",
    "    print (f\"{key} : {len(value)}\")\n",
    "\n",
    "print ()\n",
    "print (\"*\" * 50)\n",
    "print (*prop_list, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25474f19-40e0-4559-abeb-7f71c6f7d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Fininshed Getting Property Embeddings....\")\n",
    "print (\"Now Loading the model for Concepts Embeddings...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4622103-5a17-4539-a2d5-19b114058655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1948c-65ff-4f8b-a81d-6b8d3619d91b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the model model to generate concept embeddings\n",
    "# Here change the concept test file the file where the test (query) concepts are loaded\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "local_con_conf_file_path = \"configs/nn_analysis/con_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "hawk_con_conf_file_path = \"configs/nn_analysis/hawk_con_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "\n",
    "hawk_bert_base_con_config_file_path = \"configs/nn_analysis/hawk_con_nn_analysis_bert_base_fine_tune_mscg_adj_gkb_config.json\"\n",
    "\n",
    "con_config = read_config(hawk_bert_base_con_config_file_path)\n",
    "con_model = load_pretrained_model(con_config)\n",
    "con_model.eval()\n",
    "con_model.to(device)\n",
    "print (\"Concept Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d9e1e-d856-4999-90ce-0791bc0dfef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "con_list, con_emb, _, _ = get_embedding(con_model, con_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4dcab-1f15-41b8-9ba6-c6fb1b504242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"con_list len - {len(con_list)}, con_emb Len - {len(con_emb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9c1bd-f0de-447e-9b9f-e0aef89354dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trans = transform(con_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9cc784-b31d-4598-adf2-ba7a83746b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_name_emb_dict = {\"name_list_con\" : con_list,\n",
    "                     \"untransformed_con_emb\": con_emb,\n",
    "                    \"transformed_con_emb\" : con_trans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2562127-9f79-4044-9fd3-d9d308f80c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data/evaluation_data/nn_analysis/mcrae_bert_base_test_cons_embeds.pkl\", \"wb\") as f:\n",
    "    pickle.dump(con_name_emb_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacaeaa-359c-438c-a87f-a45a629c447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in con_name_emb_dict.items():\n",
    "    print (f\"{key} : {len(value)}\")\n",
    "\n",
    "print ()\n",
    "print (\"*\" * 50)\n",
    "print (*con_list, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3950b8-9895-47da-88a0-60b1abc37cfc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f244a-018b-4294-bbf8-68f736be1aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51977b3-ee31-4eef-931f-1f7cacddaae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb828ef-5b90-4ed6-b492-c3801e5f9be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b25cfe-7ed2-4665-b038-203eae76d079",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "902233a9-6e7a-43d0-8bee-b733b0cf13b3",
   "metadata": {},
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0683bd7-af59-4b50-910a-3af3272055ac",
   "metadata": {},
   "source": [
    "\n",
    "hd_con_emb_file = \"/home/amitgajbhiye/cardiff_work/dot_product_model_nn_analysis/paper_concepts_name_emb.pickle\"\n",
    "hd_prop_emb_file = \"/home/amitgajbhiye/cardiff_work/dot_product_model_nn_analysis/paper_noun_properties.pkl\"\n",
    "\n",
    "with open(hd_con_emb_file, \"rb\") as con_emb, open(hd_prop_emb_file, \"rb\") as prop_emb:\n",
    "    \n",
    "    con_name_emb = pickle.load(con_emb)\n",
    "    prop_name_emb = pickle.load(prop_emb)\n",
    "\n",
    "print (con_name_emb.keys())\n",
    "print (prop_name_emb.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3278011-6103-4f60-a610-0fe8443d70a0",
   "metadata": {},
   "source": [
    "print (f'Number of Properties in the loaded prop pickel : {len(prop_name_emb.get(\"name_list_prop\"))}', flush=True)\n",
    "print (f'Number of Untransformed Properties Embedding in the loaded prop pickel : {len(prop_name_emb.get(\"untransformed_prop_emb\"))}', flush=True)\n",
    "print (f'Number of TRansformed Properties Embedding in the loaded prop pickel : {len(prop_name_emb.get(\"transformed_prop_emb\"))}', flush=True)\n",
    "\n",
    "print ()\n",
    "print (f'Number of Concepts in the loaded con pickel : {len(con_name_emb.get(\"name_list_con\"))}', flush=True)\n",
    "print (f'Number of Untransformed Concepts Embedding in the loaded prop pickel : {len(con_name_emb.get(\"untransformed_con_emb\"))}', flush=True)\n",
    "print (f'Number of Transformed Concepts Embedding in the loaded prop pickel : {len(con_name_emb.get(\"transformed_con_emb\"))}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d3ba9-ee37-4db7-a369-1232d29a4a9c",
   "metadata": {},
   "source": [
    "prop_name_emb.get(\"transformed_prop_emb\")[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42ed58-b6ab-4164-be52-ae3808243e99",
   "metadata": {},
   "source": [
    "prop_list = prop_name_emb.get(\"name_list_prop\")\n",
    "del prop_name_emb.get(\"transformed_prop_emb\")[(prop_list.index(\"fruit.\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b006595-7684-444a-b9c3-89e201a14131",
   "metadata": {},
   "source": [
    "# Learning Nearest Neighbours\n",
    "num_nearest_neighbours = 10\n",
    "nbrs = NearestNeighbors(n_neighbors=num_nearest_neighbours, algorithm='brute').fit(np.array(prop_name_emb.get(\"transformed_prop_emb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c1a87-8106-4254-b772-f2a023cc206a",
   "metadata": {},
   "source": [
    "distances, indices = nbrs.kneighbors(np.array(con_name_emb.get(\"transformed_con_emb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0283bf15-e142-4abb-9939-763bb937db13",
   "metadata": {
    "tags": []
   },
   "source": [
    "print (indices)\n",
    "print (indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e5eea-fe36-41d7-a425-874e3981e9db",
   "metadata": {},
   "source": [
    "print (con_name_emb.keys())\n",
    "print (prop_name_emb.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6554e337-bb07-43ac-a987-58f952241e9a",
   "metadata": {},
   "source": [
    "len(prop_name_emb.get(\"untransformed_prop_emb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7c2d8-5a62-468d-b072-3461d3c02104",
   "metadata": {},
   "source": [
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):    \n",
    "    print (f\"{con} : {[prop_name_emb.get('name_list_prop') [prop_id] for prop_id in idx]}\\n\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8bc240-23b6-4ac8-80f3-2c0b76d66486",
   "metadata": {
    "tags": []
   },
   "source": [
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):\n",
    "    \n",
    "    # print (f\"{con} : {[prop_name_emb.get('name_list_prop') [prop_id] for prop_id in idx]}\\n\", flush=True)\n",
    "    \n",
    "    prop_list = [prop_name_emb.get('name_list_prop') [prop_id] for prop_id in idx]\n",
    "    \n",
    "    # prop_list = [prop.replace(\".\", \"\") for prop in prop_list]\n",
    "    \n",
    "    print (con , \":\", prop_list)\n",
    "    \n",
    "    \n",
    "    print ()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f2c9f0-d472-40a1-81aa-6305344b9f94",
   "metadata": {
    "tags": []
   },
   "source": [
    "d = {}\n",
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):\n",
    "    d[con] = [prop_name_emb.get('name_list_prop') [prop_id].strip() for prop_id in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676446f2-8e16-451a-af1b-4267f954db70",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "def pos_tagger(x):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    # print (\"tokens :\", tokens)\n",
    "    # print (\"pos tags :\", nltk.pos_tag(tokens))\n",
    "    return nltk.pos_tag(tokens)\n",
    "    \n",
    "\n",
    "def filter_prop (con, prop_list):\n",
    "    \n",
    "    filtered_prop_list = []\n",
    "    \n",
    "    filtered_prop_ends_in_adj = []\n",
    "    filtered_hyp_ends_in_noun = []\n",
    "    \n",
    "    con = con.lower().strip()\n",
    "    prop_list = [prop.lower().strip() for prop in prop_list]\n",
    "    \n",
    "    for prop in prop_list:\n",
    "        if (con not in prop) and (prop not in con) :\n",
    "            # print (f\"{con} : {prop}, {pos_tagger(prop)}, {pos_tagger(prop)[-1]}\")\n",
    "            \n",
    "            if pos_tagger(prop)[-1][1] in (\"NN\",\"NNS\",\"NNPS\"):\n",
    "                filtered_prop_list.append(prop)\n",
    "                filtered_hyp_ends_in_noun.append(prop)\n",
    "            elif pos_tagger(prop)[-1][1] in (\"JJ\"):\n",
    "                filtered_prop_ends_in_adj.append(prop)\n",
    "        \n",
    "            # print (f\"filtered_prop_list : {filtered_prop_list}\")\n",
    "    \n",
    "    print (\"Property :\", filtered_prop_ends_in_adj)\n",
    "    print (\"Hypernym :\", filtered_hyp_ends_in_noun)\n",
    "    print (\"*\"*20)\n",
    "    print ()\n",
    "    \n",
    "    \n",
    "    # print (len(filtered_prop_list))\n",
    "    # print (filtered_prop_list)\n",
    "    # print ()\n",
    "    \n",
    "#     filtered_prop_list = [prop.strip() for prop in filtered_prop_list]\n",
    "\n",
    "#     if len(filtered_prop_list) >= 15:\n",
    "#         return filtered_prop_list[0:15]\n",
    "#     else:\n",
    "#         return filtered_prop_list\n",
    "\n",
    "    \n",
    "\n",
    "d = {}\n",
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):\n",
    "    \n",
    "    filtered_prop_list = []\n",
    "    \n",
    "    prop_for_con = [prop_name_emb.get('name_list_prop') [prop_id].strip() for prop_id in idx]\n",
    "    \n",
    "    print (f\"concept : {con}\")\n",
    "    # print (f\"All properties : {prop_for_con}\")\n",
    "    # print ([pos_tagger(prop) for prop in prop_for_con])\n",
    "    filtered_prop_list = filter_prop(con, prop_for_con)\n",
    "    \n",
    "    d[con] = filtered_prop_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711aa655-8e26-4332-81c1-32bd9105f792",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d3245ef-fa63-417a-b3a2-8e81ed257c0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7055f318-d694-4b18-8534-a244525dae92",
   "metadata": {
    "tags": []
   },
   "source": [
    "l = []\n",
    "for key, value in d.items():\n",
    "    print (f\"{key} : {len(value)}\")\n",
    "    \n",
    "    l.append(len(value))\n",
    "\n",
    "counts = Counter(l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d20a5b-65b2-446e-a356-4aff89424ffa",
   "metadata": {},
   "source": [
    "print (counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41d56f8-ac29-439b-a523-96b67c8937fc",
   "metadata": {},
   "source": [
    "print (len(d.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410de647-353f-46b9-8adf-bb03c4c25606",
   "metadata": {},
   "source": [
    "df = pd.DataFrame.from_dict(d, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9489ca-4d38-4e28-b06d-4cd6581f2a09",
   "metadata": {},
   "source": [
    "print (list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e2a47-a6a6-4c9a-8dc8-eb239274dd68",
   "metadata": {},
   "source": [
    "df.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa883539-43cb-4a68-a549-a66ac21fcaa8",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b4254-35ff-4f85-b7df-bff01e41f1ae",
   "metadata": {},
   "source": [
    "hypo_hyper_file_name = \"/home/amitgajbhiye/cardiff_work/dot_product_model_nn_analysis/filtered_hd_test_results.csv\"\n",
    "columns =[\"hypo\",\"hyp=1\",\"hyp=2\",\"hyp=3\",\"hyp=4\",\"hyp=5\",\"hyp=6\",\"hyp=7\",\"hyp=8\",\"hyp=9\",\"hyp=10\",\"hyp=11\",\"hyp=12\",\"hyp=13\",\"hyp=14\",\"hyp=15\"]\n",
    "\n",
    "df.columns = columns\n",
    "\n",
    "df[\"hypo\"] = df[\"hypo\"].str.strip()\n",
    "\n",
    "df.to_csv(hypo_hyper_file_name, sep = \",\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1ed77-3d29-4d04-b84a-4eaecd3d2097",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca431373-4169-4d65-a553-151d72b805bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3854e7e-d45e-4b83-b598-16990acd6623",
   "metadata": {},
   "source": [
    "for idx, con in zip(indices, con_name_emb.get(\"name_list_con\")):\n",
    "    print (f\"{con} : {[prop_name_emb.get('name_list_prop') [prop_id] for prop_id in idx]}\\n\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4922f6-5538-4252-8e20-c0f0204ccd83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99df6604-1c19-4065-886a-91e35d5095fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c22d13-4ddd-429d-8149-9e60fe384f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (10):\n",
    "    if i == 3:\n",
    "        continue\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63c10e-1978-4569-b6c5-c40ea684df79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4668a2f1-eac9-4821-bdcc-3c8e523d09e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
