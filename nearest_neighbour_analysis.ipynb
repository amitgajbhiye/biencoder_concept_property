{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c70dfc-77c5-4b43-aa9e-4e87ad7eaf5f",
   "metadata": {},
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\")\n",
    "model.save_pretrained(\"/home/amitgajbhiye/cardiff_work/100k_data_experiments/bert_large_uncased_pretrained/model/\")\n",
    "tok = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "tok.save_pretrained(\"/home/amitgajbhiye/cardiff_work/100k_data_experiments/bert_large_uncased_pretrained/tokenizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c052c-f88c-43f4-a467-07d882f5ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "from model.concept_property_model import ConceptPropertyModel\n",
    "from utils.functions import create_model\n",
    "from utils.functions import load_pretrained_model\n",
    "from utils.functions import read_config\n",
    "from utils.functions import mcrae_dataset_and_dataloader\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# assert os.environ[\"CONDA_DEFAULT_ENV\"] == \"gvenv\", \"Activate 'gvenv' conda environment\"\n",
    "\n",
    "print (f\"Device Name : {device}\")\n",
    "print (f\"Conda Environment Name : {os.environ['CONDA_DEFAULT_ENV']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b74a83-2144-40f8-9ec0-33536d84c147",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pos_tagger(x):\n",
    "    \n",
    "    tokens = nltk.word_tokenize(x)\n",
    "    # print (\"tokens :\", tokens)\n",
    "    # print (\"pos tags :\", nltk.pos_tag(tokens))\n",
    "    return nltk.pos_tag(tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b0e61-2bf5-49a0-9c33-fd99387ef82d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tag_adj(pos_tag_list):\n",
    "    \n",
    "    tags = [word_tag[1] for word_tag in pos_tag_list]\n",
    "    # print (\"tags :\", tags)\n",
    "    # print ([tag == \"JJ\" for tag in tags])\n",
    "    # print (all([tag == \"JJ\" for tag in tags]))\n",
    "    \n",
    "    if all ([tag == \"JJ\" for tag in tags]):\n",
    "        # print (f\"Returning True : {tags}\")\n",
    "        return True\n",
    "    else:\n",
    "        # print (f\"Returning False : {tags}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbff9b7-8be0-47ad-88f0-7671dca0115c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to count properties\n",
    "\n",
    "local_files_list = [\"data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\",\n",
    "             \"data/train_data/500k_MSCG/gkb_prop_500k_train.tsv\"]\n",
    "\n",
    "prefix_adj_local_files_list = [\"data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\"]\n",
    "\n",
    "hawk_files_list = [\"/scratch/c.scmag3/biencoder_concept_property/data/train_data/500k_MSCG/mscg_prefix_adj_41k_train.tsv\",\n",
    "             \"/scratch/c.scmag3/biencoder_concept_property/data/train_data/500k_MSCG/gkb_prop_500k_train.tsv\"]\n",
    "\n",
    "def read_con_prop_data (files_list):\n",
    "    \n",
    "    df_list = []\n",
    "    for i, file in enumerate(files_list):\n",
    "        df_list.append(pd.read_csv(file, sep=\"\\t\", names=[\"concept\", \"property\"]))\n",
    "        \n",
    "    print (f\"Shapes of the DF read : {[df.shape for df in df_list]}\")\n",
    "    \n",
    "    df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    print (f\"Columns in concatenated DF : {df.columns}\")\n",
    "    print (f\"Concatenated DF shape : {df.shape}\")\n",
    "    \n",
    "    df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "    df.drop_duplicates(subset=['concept', 'property'], keep=\"first\", inplace=True)\n",
    "    \n",
    "    df[\"prop_count\"] = -1\n",
    "    \n",
    "    unique_property = df[\"property\"].unique()\n",
    "    \n",
    "    print (\"num_unique_property :\", unique_property.shape, flush=True)\n",
    "    print (\"unique_property :\", unique_property, flush=True)\n",
    "    \n",
    "    df.set_index(\"property\", inplace=True)\n",
    "    \n",
    "    for i, prop in enumerate(unique_property):\n",
    "        df.loc[prop, \"prop_count\"] = df.loc[prop].shape[0]\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    df = df[[\"concept\", \"property\", \"prop_count\"]]\n",
    "    \n",
    "    df.to_csv(\"data/evaluation_data/nn_analysis/only_prefix_adj_with_prop_count.tsv\", sep='\\t', index=None, header=True)\n",
    "\n",
    "# read_con_prop_data(files_list=prefix_adj_local_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2d4d2-55fc-41b7-afc5-794073f48ae3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_top_k_properties(con_prop_file, pos_tag = False, cut_off = 5):\n",
    "    \n",
    "    df = pd.read_csv(con_prop_file, sep=\"\\t\", header=0)\n",
    "\n",
    "    # df.sort_values(\"prop_count\", ascending=False, inplace=True)\n",
    "\n",
    "    # print (f\"DF sorted on prop count : {df}\")\n",
    "\n",
    "    df_prop_count_cut_off = df[df[\"prop_count\"] >= cut_off]\n",
    "    \n",
    "    # df_prop_count_cut_off = df_prop_count_cut_off[0:2000]\n",
    "\n",
    "    print (f\"Dataframe with prop_count >= {cut_off} = {df_prop_count_cut_off.shape}\")\n",
    "    \n",
    "    if pos_tag:\n",
    "        df_prop_count_cut_off[\"pos_tag\"] = df_prop_count_cut_off[\"property\"].apply(pos_tagger)\n",
    "        df_prop_count_cut_off[\"is_only_adj\"] = df_prop_count_cut_off[\"pos_tag\"].apply(tag_adj)\n",
    "        df_prop_count_cut_off = df_prop_count_cut_off[df_prop_count_cut_off[\"is_only_adj\"] == True]\n",
    "        \n",
    "        adj_true_df = df_prop_count_cut_off[df_prop_count_cut_off[\"is_only_adj\"] == True]\n",
    "        \n",
    "        print (f\"adj_true_df shape {adj_true_df.shape}\")\n",
    "        print (f\"adj_true_df['property'].unique - len :\", adj_true_df['property'].unique().shape)\n",
    "        \n",
    "    \n",
    "    df_prop_count_cut_off.to_csv(\"data/evaluation_data/nn_analysis/df_with_tags.tsv\", sep=\"\\t\", index=False)\n",
    "    print (df_prop_count_cut_off)\n",
    "    \n",
    "    unique_properties = df_prop_count_cut_off[\"property\"].unique()\n",
    "    unique_properties = [x.strip().replace(\"(part)\", \"\").replace(\".\", \"\") for x in unique_properties]\n",
    "    num_unique_properties = df_prop_count_cut_off[\"property\"].unique().shape\n",
    "\n",
    "    print (f\"Number of unique properties in cut_off DF : {num_unique_properties}\")\n",
    "    # print (f\"Unique Properties are : {unique_properties}\")\n",
    "    \n",
    "    df_list = [(\"dummy\", prop, 0) for prop in unique_properties]\n",
    "\n",
    "    df_prop = pd.DataFrame.from_records(df_list)\n",
    "\n",
    "    df_prop.to_csv(\"data/evaluation_data/nn_analysis/adjs_prop_count_5_prefix_adj_plus_gkb_prop_with_prop_count.tsv\", sep=\"\\t\", index=None, header=None)\n",
    "\n",
    "# get_top_k_properties(\"data/evaluation_data/nn_analysis/hd_data/prefix_adj_plus_gkb_prop_with_prop_count.tsv\", pos_tag=True, cut_off=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb8b3d-5230-4e69-ac2a-4f5dae6963c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hd_vocab_file = \"data/evaluation_data/nn_analysis/hd_data/1A.english.vocabulary.txt\"\n",
    "test_file = \"data/evaluation_data/nn_analysis/hd_data/hd_concept_test.csv\"\n",
    "\n",
    "def preprocess_hd_data(vocab_file, test_concept_file):\n",
    "\n",
    "    with open(vocab_file,  \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [(\"con_dummy\", prop.strip(), int(0)) for prop in lines]\n",
    "        \n",
    "    con_prop_vocab_df = pd.DataFrame.from_records(lines)\n",
    "    # con_prop_vocab_df = pd.DataFrame.from_records(lines)[0:2500]\n",
    "    \n",
    "    con_prop_vocab_df.to_csv(\"data/evaluation_data/nn_analysis/hd_data/properties_hd_vocab_con_prop.tsv\", sep=\"\\t\", index=None, header=None)\n",
    "    \n",
    "    \n",
    "    test_concepts_df = pd.read_csv(test_concept_file, sep=\",\", header=0)\n",
    "    print (f\"Test Concepts DF shape : {test_concepts_df.shape}\")\n",
    "    \n",
    "    test_cons_list = test_concepts_df[\"hypo\"].unique()\n",
    "    # test_cons_list = test_concepts_df[\"hypo\"].unique()[0:10]\n",
    "    \n",
    "    \n",
    "    print (f\"Num Test Concepts : {len(test_cons_list)}\")\n",
    "    \n",
    "    test_con_prop_list = [(con.strip(), \"prop_dummy\", int(0)) for con in test_cons_list]\n",
    "    \n",
    "    test_con_prop_df  = pd.DataFrame.from_records(test_con_prop_list)\n",
    "    \n",
    "    test_con_prop_df.to_csv(\"data/evaluation_data/nn_analysis/hd_data/concepts_hd_test_con_prop.tsv\", sep=\"\\t\", index=None, header=None)\n",
    "    \n",
    "    \n",
    "# preprocess_hd_data (vocab_file = hd_vocab_file, test_concept_file= test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539215f-2234-4fd5-9776-5ca2293c9bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the BERT Large Model for generating Property Embedding\n",
    "# Here change the property test_file in config to the tsv file which contain the properties\n",
    "\n",
    "local_prop_config_file_path = \"configs/nn_analysis/prop_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "hawk_prop_config_file_path = \"configs/nn_analysis/hawk_prop_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "prop_config = read_config(hawk_prop_config_file_path)\n",
    "prop_model = load_pretrained_model(prop_config)\n",
    "prop_model.eval()\n",
    "prop_model.to(device)\n",
    "print(\"Property Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d02813-c5d3-4b32-b31b-9027f26f15fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the embeddings for property and concepts\n",
    "\n",
    "def get_embedding (model, config):\n",
    "    \n",
    "    print (f\"Config in get_embedding function : {config}\")\n",
    "    \n",
    "    test_dataset, test_dataloader = mcrae_dataset_and_dataloader(\n",
    "        dataset_params=config.get(\"dataset_params\"),\n",
    "        dataset_type=\"test\",\n",
    "        data_df=None,\n",
    "    )\n",
    "    \n",
    "    con_list, con_emb, prop_list, prop_emb = [], [], [], []\n",
    "\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "\n",
    "        concepts_batch, property_batch = test_dataset.add_context(batch)\n",
    "\n",
    "        ids_dict = test_dataset.tokenize(concepts_batch, property_batch)\n",
    "\n",
    "        (\n",
    "            concept_inp_id,\n",
    "            concept_attention_mask,\n",
    "            concept_token_type_id,\n",
    "            property_input_id,\n",
    "            property_attention_mask,\n",
    "            property_token_type_id,\n",
    "        ) = [val.to(device) for _, val in ids_dict.items()]\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            concept_embedding, property_embedding, logits = model(\n",
    "                concept_input_id=concept_inp_id,\n",
    "                concept_attention_mask=concept_attention_mask,\n",
    "                concept_token_type_id=concept_token_type_id,\n",
    "                property_input_id=property_input_id,\n",
    "                property_attention_mask=property_attention_mask,\n",
    "                property_token_type_id=property_token_type_id,\n",
    "            )\n",
    "            \n",
    "            print()\n",
    "            print (f\"Concepts Data :\", len(batch[0]))\n",
    "            print (f\"Concepts Data :\", batch[0])\n",
    "            print (f\"concept_embedding.shape : {concept_embedding.shape}\")\n",
    "            \n",
    "            print (f\"Property Data :\", len(batch[1]))\n",
    "            print (f\"Property Data :\", batch[1])\n",
    "            print (f\"property_embedding.shape : {property_embedding.shape}\")\n",
    "            \n",
    "            # con_vec = [(con, vec) for con, vec in zip (batch[0], concept_embedding)]    \n",
    "            # prop_vec = [(prop, vec) for prop, vec in zip(batch[1], property_embedding)]\n",
    "            \n",
    "            con_list.extend(batch[0])\n",
    "            con_emb.extend(concept_embedding)\n",
    "            \n",
    "            prop_list.extend(batch[1])\n",
    "            prop_emb.extend(property_embedding)\n",
    "            \n",
    "    con_emb = [x.cpu().numpy() for x in con_emb]\n",
    "    prop_emb = [x.cpu().numpy() for x in prop_emb]\n",
    "    \n",
    "    return con_list, con_emb, prop_list, prop_emb\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc60cda-01ab-43a0-850b-ddde1df8cc84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, _, prop_list, prop_emb = get_embedding(prop_model, prop_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48621c5d-00c1-4dec-bda2-f9b53b8743e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"prop_list len - {len(prop_list)}, Property Emb Len - {len(prop_emb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b67cb8-4477-4f5a-94cd-d3d003ac2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(vecs):\n",
    "    \n",
    "    maxnorm = max([np.linalg.norm(v) for v in vecs])\n",
    "    new_vecs = []\n",
    "    \n",
    "    for v in vecs:\n",
    "        new_vecs.append(np.insert(v, 0, np.sqrt(maxnorm**2-np.linalg.norm(v)**2)))\n",
    "    \n",
    "    return new_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dd36fb-5752-497f-ad29-d35afc9e732a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_trans = transform(prop_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ee2fa-7b19-42eb-a155-987f1e6e893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_name_emb_dict = {\"prop_name_list\" : prop_list, \n",
    "                     \"prop_transformed_emb\" : prop_trans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1eb268-a0fa-4f10-9fc4-5062b0a9e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Pickling the transformed property name list and their embeddings.\")\n",
    "\n",
    "with open (\"data/evaluation_data/nn_analysis/hd_data/hd_prop_name_emb.pickle\", \"wb\") as f:\n",
    "    pickle.dump(prop_name_emb_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a628bda-a327-484c-8c8a-be5745d56238",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in prop_name_emb_dict.items():\n",
    "    print (f\"{key} : {len(value)}\")\n",
    "\n",
    "print ()\n",
    "print (\"*\" * 50)\n",
    "print (*prop_list, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2b3ca-f28b-4cc9-a17a-ca3c96802f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b1b46-d79a-4fbf-b1ce-32056bc61804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88e6863a-79a9-4f4a-91b9-3d31d14322a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading the model model to generate concept embeddings\n",
    "# Here change the concept test file the file where the test (query) concepts are loaded\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "local_con_conf_file_path = \"configs/nn_analysis/con_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "hawk_con_conf_file_path = \"configs/nn_analysis/hawk_con_nn_analysis_bert_large_fine_tune_mscg_adj_gkb_config.json\"\n",
    "\n",
    "con_config = read_config(local_con_conf_file_path)\n",
    "con_model = load_pretrained_model(con_config)\n",
    "con_model.eval()\n",
    "con_model.to(device)\n",
    "print (\"Concept Model Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8c60b-f134-43ef-ad39-4ca6fdcd4f82",
   "metadata": {
    "tags": []
   },
   "source": [
    "con_list, con_emb, _, _ = get_embedding(con_model, con_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e485c0-2017-427b-90b7-0e5939fdf747",
   "metadata": {},
   "source": [
    "print (f\"con_list len - {len(con_list)}, con_emb Len - {len(con_emb)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9e776-c14e-405b-a050-7ba2289b6ae5",
   "metadata": {},
   "source": [
    "con_trans = transform(con_emb)\n",
    "assert len(con_list) == len(con_trans)\n",
    "print (len(con_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8971371-daf2-4e09-9fa8-eb4c2b96ffec",
   "metadata": {},
   "source": [
    "con_name_emb_dict = {\"con_name_list\" : con_list,\n",
    "                    \"con_transformed_emb\" : con_trans}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f8398-a651-4eba-ac76-f5a812a32edf",
   "metadata": {
    "tags": []
   },
   "source": [
    "con_name_emb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8d349-7005-43d8-a301-71abcede49bd",
   "metadata": {},
   "source": [
    "with open (\"data/evaluation_data/nn_analysis/hd_data/hd_con_name_emb.pickle\", \"wb\") as f:\n",
    "    pickle.dump(con_name_emb_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9030dd-35cb-43b0-8096-6b690b0a61b6",
   "metadata": {},
   "source": [
    "with open(\"data/evaluation_data/nn_analysis/hd_data/hd_con_name_emb.pickle\", \"rb\") as con_emb, \\\n",
    "    open(\"data/evaluation_data/nn_analysis/hd_data/hd_prop_name_emb.pickle\", \"rb\") as prop_emb:\n",
    "    \n",
    "    con_name_emb = pickle.load(con_emb)\n",
    "    prop_name_emb = pickle.load(prop_emb)\n",
    "\n",
    "print (con_name_emb.keys())\n",
    "print (prop_name_emb.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7d6b7-2804-4ba9-a345-5db019127537",
   "metadata": {},
   "source": [
    "logits = (concept_mask_vector * property_mask_vector).sum(-1).reshape(concept_mask_vector.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab1070-f2f7-49ff-9303-b3b073e38577",
   "metadata": {},
   "source": [
    "con_embs = torch.tensor(con_name_emb.get(\"con_transformed_emb\"))\n",
    "con_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21c1dc-9386-4bb9-91a1-6f2467b6cd12",
   "metadata": {},
   "source": [
    "prop_embs = torch.tensor(prop_name_emb.get(\"prop_transformed_emb\"))\n",
    "prop_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edeb35e-d314-4f4d-8e1b-dbfc3a7e47b8",
   "metadata": {},
   "source": [
    "l = (con_embs * prop_embs).sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ded10-f4ac-4963-aa5a-755f678c0399",
   "metadata": {},
   "source": [
    "print (f'Number of Properties in the loaded prop pickel : {len(prop_name_emb.get(\"prop_name_list\"))}', flush=True)\n",
    "print (f'Number of Properties Embedding in the loaded prop pickel : {len(prop_name_emb.get(\"prop_transformed_emb\"))}', flush=True)\n",
    "\n",
    "print (f'Number of Concepts in the loaded con pickel : {len(con_name_emb.get(\"con_name_list\"))}', flush=True)\n",
    "print (f'Number of Concepts Embedding in the loaded prop pickel : {len(con_name_emb.get(\"con_transformed_emb\"))}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f1405-f1fe-464f-99b0-c7595e7377a7",
   "metadata": {},
   "source": [
    "num_nearest_neighbours = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dbf521-0b9b-4b75-a7fa-a181132ae045",
   "metadata": {},
   "source": [
    "# Learning Nearest Neighbours\n",
    "nbrs = NearestNeighbors(n_neighbors=num_nearest_neighbours, algorithm='brute').fit(np.array(prop_name_emb.get(\"prop_transformed_emb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad1315-91a8-472e-b293-12cfa40e85dd",
   "metadata": {},
   "source": [
    "distances, indices = nbrs.kneighbors(np.array(con_name_emb.get(\"con_transformed_emb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc68892-7980-47f9-83cd-f5ba21576b35",
   "metadata": {},
   "source": [
    "print (indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69ea4c-1fb7-4096-beec-d36f00351bf9",
   "metadata": {},
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad03267-6d28-494a-af2f-a0d6762564b3",
   "metadata": {},
   "source": [
    "for idx, con in zip(indices, con_name_emb.get(\"con_name_list\")):\n",
    "    print (f\"{con} : {[prop_name_emb.get('prop_name_list') [prop_id] for prop_id in idx]}\\n\", flush=True)\n",
    "\n",
    "\n",
    "generated_hypernyms_file = \"data/evaluation_data/nn_analysis/hd_data/hd_test_concepts_generated_hypernyms_file.txt\"\n",
    "\n",
    "with open(generated_hypernyms_file, \"w\") as file:\n",
    "    for idx, con in zip(indices, con_name_emb.get(\"con_name_list\")):\n",
    "        file.write(f\"{con} : {[prop_name_emb.get('prop_name_list') [prop_id] for prop_id in idx]}\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
