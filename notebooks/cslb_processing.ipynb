{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a056e-c2b8-4627-aa2f-b0213907e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9230d51-520c-427a-8225-ab6422a08641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh ./../../data/CSLB_Property_Norms_V1.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407da99a-8ba9-469e-8da9-b9fd986b36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file_path = \"/home/amitgajbhiye/cardiff_work/data/CSLB_Property_Norms_V1.1/norms.dat\"\n",
    "hawk_file_path = \"CSLB_Property_Norms_V1.1/norms.dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6c739e-7f12-48f6-b965-38d64484e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(concept, feature_alternatives, participant_list):\n",
    "    \n",
    "    # print (concept)\n",
    "    # print (feature_alternatives.split(\";\"))\n",
    "    # print (participant_list.split(\"/\"))\n",
    "    # print ()\n",
    "    \n",
    "    # print (f\"Processing Record : {concept, feature_alternatives, participant_list}\")\n",
    "    feature_list = feature_alternatives.split(\";\")\n",
    "    feature_list = [x.strip() for x in feature_list]\n",
    "    # print (f\"feature_list : {feature_list}\")\n",
    "    participant_list = participant_list.split(\"/\")\n",
    "    # print (f\"participant_list 1: {participant_list}\")\n",
    "    participant_list = [len(x.replace(\"p\", \"\").strip().split()) for x in participant_list]\n",
    "    # print (f\"participant_list 2: {participant_list}\")\n",
    "    \n",
    "    max_value = max (participant_list)\n",
    "    # print (f\"max_value : {max_value}\")\n",
    "    \n",
    "    concept_data = []\n",
    "    if max_value >= 3:\n",
    "        max_index = participant_list.index(max_value)\n",
    "        # print (\"feature_list :\", feature_list)\n",
    "        # print (f\"max_index :\", {max_index})\n",
    "        # print (f\"max_value : {max_value}\")\n",
    "        feature = feature_list[max_index]\n",
    "        # print (f\"feature_list : {feature_list}\")\n",
    "        # print (f\"feature: {feature}\")\n",
    "        # print ()\n",
    "        \n",
    "        concept_data.append((concept.strip(), feature.strip(), max_value))\n",
    "    \n",
    "    return concept_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9b83d-e062-450e-b4b2-bf5aa7a0a4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cslb_processing(file_path):\n",
    "    \n",
    "    df = pd.read_csv(file_path, sep=\"\\t\", header=\"infer\")\n",
    "    \n",
    "    all_data_list = [process_row(row[0], row[1], row[2]) for row in zip(df[\"concept\"], df[\"feature alternatives\"], df[\"participant list\"])]\n",
    "    \n",
    "    all_data_list = [con_feature_count for sublist in all_data_list for con_feature_count in sublist]\n",
    "    # print (all_data_list)\n",
    "    \n",
    "    all_data_df = pd.DataFrame.from_records(all_data_list, columns=[\"concept\", \"property\", \"participant_count\"])\n",
    "    \n",
    "    \n",
    "    print (\"Original CSLB Dataframe size : \", df.shape)\n",
    "    print (\"Processed Data Before Removing Duplicates :\", all_data_df.shape)\n",
    "    \n",
    "    duplicated_df = all_data_df.loc[all_data_df.duplicated(subset = [\"concept\", \"property\"], keep=False)]\n",
    "    duplicates_df_idx = duplicated_df.index\n",
    "    \n",
    "    all_data_df = all_data_df.drop(index=duplicates_df_idx)\n",
    "    all_data_df = all_data_df.dropna(axis=0, how=\"any\")\n",
    "    all_data_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    print (\"Duplicated Data :\", duplicated_df.shape)\n",
    "    \n",
    "    print (\"Data after After Removing Duplicates :\", all_data_df.shape)\n",
    "    \n",
    "    return all_data_df\n",
    "\n",
    "df_cslb = cslb_processing(file_path=hawk_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7b1e1-5e77-456a-aced-b101abff6086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (df_cslb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c3605-1f95-4b70-b014-b71d1742eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cslb.drop(\"participant_count\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88198d9c-a72e-4fcf-939c-ac7791c31212",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6e7d0-28ae-46e0-a6b6-22d0c63c10eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def negative_sampling(df, data_type, num_negative=5):\n",
    "    \n",
    "    pos_data_list = df.values.tolist()\n",
    "    \n",
    "    df[\"label\"] = int(1)\n",
    "    \n",
    "    # df.reset_index(drop=True, inplace=True)\n",
    "    print (df.shape)\n",
    "    print (df.head())\n",
    "    print ()\n",
    "    \n",
    "    unique_concepts = df[\"concept\"].unique()\n",
    "    unique_properties = df[\"property\"].unique()\n",
    "    \n",
    "    print (f\"Number of Unique Concepts in Dataframe :\", len(unique_concepts))\n",
    "    \n",
    "    all_negative_data = []\n",
    "    \n",
    "    for concept in unique_concepts:\n",
    "        \n",
    "        concept_data = df[df[\"concept\"] == concept]\n",
    "        num_record = len(concept_data)\n",
    "        \n",
    "        print()\n",
    "        print (f\"Generating Negative Data for Concept : {concept}\")\n",
    "        print (f\"Postive data for concept in DF : {concept_data.shape}\")\n",
    "        \n",
    "        total_neg_num = num_record * num_negative\n",
    "        \n",
    "        print (f\"Total Number of Negative Records to be generated : {total_neg_num}\")\n",
    "        \n",
    "        rest_df = df[df[\"concept\"] != concept]\n",
    "        print (f\"rest_df.shape : {rest_df.shape}\")\n",
    "        \n",
    "        concept_neg_data = []\n",
    "        \n",
    "        while (True):\n",
    "            \n",
    "            concept = concept.strip()\n",
    "            neg_properties = list(rest_df[\"property\"].sample(n = total_neg_num))\n",
    "            \n",
    "            neg_data = [[concept, neg_prop] for neg_prop in neg_properties]\n",
    "            print (f\"neg_data length :\", len(neg_data))\n",
    "            \n",
    "            if len(concept_neg_data) < total_neg_num:\n",
    "                for x in neg_data:\n",
    "                    if not (x in pos_data_list):\n",
    "                        if not (x in all_negative_data):\n",
    "\n",
    "                            all_negative_data.append(x)\n",
    "                            concept_neg_data.append(x)\n",
    "                            \n",
    "                            if len(concept_neg_data) == total_neg_num:\n",
    "                                break\n",
    "                                \n",
    "            if len(concept_neg_data) == total_neg_num:\n",
    "                break\n",
    "            \n",
    "        print (f\"Number of negative records generated : {len(concept_neg_data)}\")\n",
    "        print (f\"Negative Records\")\n",
    "        print (concept_neg_data)\n",
    "        print ()\n",
    "                        \n",
    "    \n",
    "    _ = [x.insert(2, int(0)) for x in all_negative_data]\n",
    "    \n",
    "    # print (\"all_negative_data\")\n",
    "    # print (all_negative_data)\n",
    "                                        \n",
    "    all_neg_data_df = pd.DataFrame.from_records(all_negative_data, columns=[\"concept\", \"property\", \"label\"])\n",
    "    \n",
    "    neg_data_duplicate_records = all_neg_data_df[all_neg_data_df.duplicated([\"concept\", \"property\"])]\n",
    "    \n",
    "    print ()\n",
    "    print (f\"all_neg_data_df.shape : {all_neg_data_df.shape}\")\n",
    "    print (f\"neg_data_duplicate_records.shape : {neg_data_duplicate_records.shape}\")\n",
    "    print ()\n",
    "        \n",
    "    print (f\"Checking overlap between positive and negative data\")\n",
    "    pos_neg_overlap_df = df.merge(all_neg_data_df, how = 'inner', on = [\"concept\", \"property\"], indicator=False)\n",
    "    print(f\"Positive and Negative Overlapped Dataframe\")\n",
    "    print (pos_neg_overlap_df)\n",
    "    print()\n",
    "    \n",
    "    pos_neg_df = pd.concat([df, all_neg_data_df], axis=0, ignore_index=True)\n",
    "            \n",
    "    print (\"DF after adding negative data\")\n",
    "    print (pos_neg_df.shape)\n",
    "    \n",
    "    duplicate_records = pos_neg_df[pos_neg_df.duplicated([\"concept\", \"property\"])]\n",
    "    \n",
    "    print (f\"Duplicate Records : {duplicate_records.shape}\")\n",
    "    print (f\"Duplicate record label value count: {duplicate_records['label'].value_counts()}\")\n",
    "    print()\n",
    "    \n",
    "    pos_neg_df = pos_neg_df[~pos_neg_df.duplicated(subset=[\"concept\", \"property\"], keep=\"first\")]\n",
    "    \n",
    "    print (f\"Dataframe after removing duplicates : {pos_neg_df.shape}\")\n",
    "    \n",
    "    if data_type == \"train\":\n",
    "        pos_neg_df.to_csv(\"cslb_train_pos_neg_data.tsv\", sep='\\t', index=None, header=None)\n",
    "    elif data_type == \"test\":\n",
    "        pos_neg_df.to_csv(\"cslb_test_pos_neg_data.tsv\", sep='\\t', index=None, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145692ed-41ff-4b7c-9fce-1d85e8f22db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cslb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd067e-448f-4c9d-a80a-795d6bfdaa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_concepts = df_cslb[\"concept\"].unique()\n",
    "\n",
    "print (f\"Unique Concepts : {len(unique_concepts)}\")\n",
    "\n",
    "test_concepts = np.random.choice(a=unique_concepts, size = int(0.1 * len(unique_concepts)), replace=False)\n",
    "\n",
    "print (f\"Number of test concepts : {len(test_concepts)}\")\n",
    "\n",
    "test_df = df_cslb[df_cslb[\"concept\"].isin(test_concepts)]\n",
    "train_df = df_cslb[~df_cslb[\"concept\"].isin(test_concepts)]\n",
    "\n",
    "print ()\n",
    "print (\"Total CSLB DF shape :\", df_cslb.shape)\n",
    "print (\"Train DF shape :\", train_df.shape, train_df.columns)\n",
    "print (\"Test DF shape :\", test_df.shape, test_df.columns)\n",
    "\n",
    "print (\"Checking Train Test DF Merge\")\n",
    "df1 = train_df.merge(test_df, how=\"inner\", on = [\"concept\"], indicator=False )\n",
    "\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47dd54-de8f-42f8-a11f-56686c4d314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_sampling(train_df, \"train\", num_negative=5)\n",
    "negative_sampling(test_df, \"test\", num_negative=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38007b73-b70e-41dc-be36-a6d5e4b4fdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
